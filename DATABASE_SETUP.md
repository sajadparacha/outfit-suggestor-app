# Database Setup - Outfit History Feature

## Overview
This document describes the PostgreSQL database integration for tracking outfit suggestion history.

## What Was Implemented

### 1. Database Configuration
- **Database**: PostgreSQL 15
- **ORM**: SQLAlchemy 2.0.36
- **Driver**: psycopg2-binary 2.9.10
- **Database Name**: `outfit_suggestor`
- **Connection**: `postgresql://sajad@localhost:5432/outfit_suggestor`

### 2. Database Schema

#### `outfit_history` Table
Stores all outfit suggestions generated by the AI.

| Column      | Type         | Description                                    |
|-------------|--------------|------------------------------------------------|
| id          | Integer (PK) | Auto-incrementing primary key                  |
| created_at  | DateTime     | Timestamp when suggestion was created          |
| text_input  | Text         | User's additional context/preferences          |
| shirt       | Text         | AI-suggested shirt description                 |
| trouser     | Text         | AI-suggested trouser/pants description         |
| blazer      | Text         | AI-suggested blazer/jacket description         |
| shoes       | Text         | AI-suggested shoes description                 |
| belt        | Text         | AI-suggested belt description                  |
| reasoning   | Text         | AI's explanation for the outfit recommendation |

### 3. API Endpoints

#### POST `/api/suggest-outfit`
- **Enhanced**: Now automatically saves every outfit suggestion to the database
- **Behavior**: After generating a suggestion, it's persisted with a timestamp
- **Response**: Returns the outfit suggestion (same as before)

#### GET `/api/outfit-history`
- **New Endpoint**: Retrieves outfit suggestion history
- **Query Parameters**:
  - `limit` (optional, default: 20): Maximum number of entries to return
- **Response**: JSON array of outfit history entries, sorted by most recent first
- **Example**:
  ```json
  [
    {
      "id": 1,
      "created_at": "2024-12-02T10:30:00",
      "text_input": "casual Friday look",
      "shirt": "Light blue Oxford shirt",
      "trouser": "Khaki chinos",
      "blazer": "Navy blazer",
      "shoes": "Brown leather loafers",
      "belt": "Brown leather belt",
      "reasoning": "Perfect smart-casual combination..."
    }
  ]
  ```

### 4. Files Modified/Created

#### New Files
- `backend/models/database.py` - Database configuration and session management
- `backend/models/outfit_history.py` - ORM model for outfit history table

#### Modified Files
- `backend/requirements.txt` - Added SQLAlchemy and psycopg2-binary
- `backend/config.py` - Added DATABASE_URL configuration
- `backend/main.py` - Added database initialization on startup
- `backend/routes/outfit_routes.py` - Added history saving and retrieval endpoints
- `backend/.env` - Added DATABASE_URL environment variable

## Local Development Setup

### Prerequisites
1. PostgreSQL 15 installed via Homebrew:
   ```bash
   brew install postgresql@15
   brew services start postgresql@15
   ```

2. Database created:
   ```bash
   createdb outfit_suggestor
   ```

3. Environment variable set in `backend/.env`:
   ```
   DATABASE_URL=postgresql://sajad@localhost:5432/outfit_suggestor
   ```

### Running the Application
```bash
cd backend
source venv/bin/activate
pip install -r requirements.txt
python main.py
```

The database tables will be automatically created on first startup.

## Production Deployment

### Environment Variables
Set the following in your production environment:
```
DATABASE_URL=postgresql://username:password@host:port/database_name
```

### Recommended Hosting Options
- **Railway**: Free tier available, automatic PostgreSQL provisioning
- **Render**: Free tier with PostgreSQL add-on
- **Heroku**: Hobby tier with PostgreSQL
- **Supabase**: Free tier with PostgreSQL + additional features

### Migration Strategy
For production, consider using Alembic for database migrations:
```bash
pip install alembic
alembic init alembic
# Configure alembic.ini and create migrations
```

## Testing the Feature

### 1. Generate an outfit suggestion
```bash
curl -X POST http://localhost:8001/api/suggest-outfit \
  -F "image=@/path/to/shirt.jpg" \
  -F "text_input=casual Friday"
```

### 2. View history
```bash
curl http://localhost:8001/api/outfit-history?limit=10
```

### 3. Check database directly
```bash
psql -U sajad -d outfit_suggestor -c "SELECT * FROM outfit_history;"
```

## Future Enhancements

### Potential Features
1. **User Authentication**: Associate history with specific users
2. **Favorites**: Allow users to mark favorite outfits
3. **Search**: Full-text search across outfit descriptions
4. **Analytics**: Track most popular outfit combinations
5. **Image Storage**: Store uploaded images alongside suggestions
6. **Filtering**: Filter history by date, occasion, colors, etc.
7. **Export**: Allow users to export their outfit history
8. **Sharing**: Share outfit suggestions with others

### Database Optimizations
- Add indexes on `created_at` for faster sorting
- Add indexes on `text_input` for search functionality
- Consider partitioning for large datasets
- Implement soft deletes instead of hard deletes

## Troubleshooting

### Common Issues

1. **"role 'postgres' does not exist"**
   - Solution: Update DATABASE_URL to use your actual PostgreSQL username
   - Check with: `whoami` and use that username

2. **"address already in use"**
   - Solution: Kill existing process on port 8001
   - Command: `lsof -ti:8001 | xargs kill -9`

3. **"could not connect to server"**
   - Solution: Ensure PostgreSQL is running
   - Command: `brew services start postgresql@15`

4. **Tables not created**
   - Solution: Check logs, ensure DATABASE_URL is correct
   - Manual creation: The app creates tables automatically on startup

## Branch Information
- **Branch**: `feature/outfit-history-db`
- **Base Branch**: `iphone_client`
- **Status**: Implementation complete, ready for testing

## Next Steps
1. Test the feature with real outfit suggestions
2. Update frontend to display outfit history
3. Add user authentication (optional)
4. Deploy to production with managed PostgreSQL
5. Merge to main branch after testing




